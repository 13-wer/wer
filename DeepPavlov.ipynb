{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Эксперимент с предобученной моделью их DeepPavlov.\n","\n","#### Для подготовки данных использовалась только токенизация. Исходила из предположения, что лемматизация и удаление стоп-слов усложнят задачу обнаружения плохо сгенерированного текста."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-17T11:53:02.894673Z","iopub.status.busy":"2024-05-17T11:53:02.893986Z","iopub.status.idle":"2024-05-17T11:53:02.902746Z","shell.execute_reply":"2024-05-17T11:53:02.901753Z","shell.execute_reply.started":"2024-05-17T11:53:02.894640Z"},"trusted":true},"outputs":[],"source":["# Пути к файлам с данными\n","data_file_path = '/kaggle/input/pp2-dataset/hackaton_result_dataset.xlsx'"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T11:55:07.618716Z","iopub.status.busy":"2024-05-17T11:55:07.618294Z","iopub.status.idle":"2024-05-17T11:55:07.625859Z","shell.execute_reply":"2024-05-17T11:55:07.624649Z","shell.execute_reply.started":"2024-05-17T11:55:07.618684Z"},"trusted":true},"outputs":[],"source":["# Необходимые модули\n","import pandas as pd\n","import json\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding,\n","    EarlyStoppingCallback\n",")\n","\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","import pandas as pd\n","import numpy as np\n","import evaluate\n","import torch\n","\n","from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T11:53:21.244692Z","iopub.status.busy":"2024-05-17T11:53:21.243493Z","iopub.status.idle":"2024-05-17T11:53:22.586816Z","shell.execute_reply":"2024-05-17T11:53:22.585819Z","shell.execute_reply.started":"2024-05-17T11:53:21.244654Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model_annotation</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>давай по россии значит на коленях быстро блять...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ну разве можно так с телефоном поступает</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>у меня нет с собой в полном адресе я щас дома ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>а я здесь кто я санитар</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>дежурный по кузьминскому военнокомату</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6503</th>\n","      <td>это студия</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6504</th>\n","      <td>потише говори у меня рядом течение вдруг сидит...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6505</th>\n","      <td>если в поймаю дай бог а зачем тогда будешь рез...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6506</th>\n","      <td>а ты все удобром что ли а че будет алло алло т...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6507</th>\n","      <td>вы я так понимаю в не адекватном состоянии что...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6508 rows × 2 columns</p>\n","</div>"],"text/plain":["                                       model_annotation  label\n","0     давай по россии значит на коленях быстро блять...      1\n","1              ну разве можно так с телефоном поступает      0\n","2     у меня нет с собой в полном адресе я щас дома ...      0\n","3                               а я здесь кто я санитар      0\n","4                 дежурный по кузьминскому военнокомату      0\n","...                                                 ...    ...\n","6503                                         это студия      1\n","6504  потише говори у меня рядом течение вдруг сидит...      0\n","6505  если в поймаю дай бог а зачем тогда будешь рез...      1\n","6506  а ты все удобром что ли а че будет алло алло т...      1\n","6507  вы я так понимаю в не адекватном состоянии что...      1\n","\n","[6508 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Данные\n","df = pd.read_excel(data_file_path)\n","df = df[['model_annotation', 'label']]\n","df"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T11:53:24.741401Z","iopub.status.busy":"2024-05-17T11:53:24.740741Z","iopub.status.idle":"2024-05-17T11:53:24.749490Z","shell.execute_reply":"2024-05-17T11:53:24.748153Z","shell.execute_reply.started":"2024-05-17T11:53:24.741370Z"},"trusted":true},"outputs":[],"source":["# Срздание обучающей и валидационной выборок\n","train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T11:53:26.540714Z","iopub.status.busy":"2024-05-17T11:53:26.539790Z","iopub.status.idle":"2024-05-17T11:53:28.849176Z","shell.execute_reply":"2024-05-17T11:53:28.848178Z","shell.execute_reply.started":"2024-05-17T11:53:26.540673Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd9a7ffe71084df7b00f32147007c606","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72940ab298184f81813e4b8e5acbcb00","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f676df62728540fdb1e659e347898327","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59d2deaf33ba4900a0ae1437b1fa12c3","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["# Токенизация, используется тот же токенизатор, что и в выбранной модели\n","tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n","tokenized_train = tokenizer(train_df['model_annotation'].tolist(), padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n","tokenized_test = tokenizer(valid_df['model_annotation'].tolist(), padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T11:53:30.583103Z","iopub.status.busy":"2024-05-17T11:53:30.582721Z","iopub.status.idle":"2024-05-17T11:53:30.591202Z","shell.execute_reply":"2024-05-17T11:53:30.590033Z","shell.execute_reply.started":"2024-05-17T11:53:30.583073Z"},"trusted":true},"outputs":[],"source":["# Формирование датасетов\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenized_texts, labels):\n","        self.tokenized_texts = tokenized_texts\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"input_ids\": self.tokenized_texts[\"input_ids\"][idx],\n","            \"attention_mask\": self.tokenized_texts[\"attention_mask\"][idx],\n","            \"labels\": torch.tensor(self.labels[idx]).to('cuda')\n","        }\n","\n","train_labels = train_df['label'].tolist()\n","test_labels = valid_df['label'].tolist()\n","train_dataset = CustomDataset(tokenized_train, train_labels)\n","eval_dataset = CustomDataset(tokenized_test, test_labels)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T13:22:21.151700Z","iopub.status.busy":"2024-05-17T13:22:21.150925Z","iopub.status.idle":"2024-05-17T13:22:21.186175Z","shell.execute_reply":"2024-05-17T13:22:21.185309Z","shell.execute_reply.started":"2024-05-17T13:22:21.151663Z"},"trusted":true},"outputs":[],"source":["# Аргументы для обучения модели\n","training_args = TrainingArguments(\n","    output_dir=\"output\",\n","    learning_rate=3e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=5,\n","    warmup_steps=100,\n","    weight_decay=0.02,\n","#     evaluation_strategy=\"epoch\",\n","#     save_strategy='epoch',\n","    evaluation_strategy=\"steps\",\n","    eval_steps=50,\n","    save_steps=150,\n","    remove_unused_columns=True,\n","    load_best_model_at_end=True,\n","    logging_steps=50,\n","    report_to='none',\n","    metric_for_best_model=\"roc_auc\"\n",")"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T13:22:22.152645Z","iopub.status.busy":"2024-05-17T13:22:22.152230Z","iopub.status.idle":"2024-05-17T13:22:22.158190Z","shell.execute_reply":"2024-05-17T13:22:22.157193Z","shell.execute_reply.started":"2024-05-17T13:22:22.152594Z"},"trusted":true},"outputs":[],"source":["# Функция подсчёта меткири\n","def compute_metrics(eval_pred):\n","    labels = eval_pred.label_ids\n","    probabilities = eval_pred.predictions[:, 1]  # Assuming the second column contains the probabilities for class 1\n","    roc_auc = roc_auc_score(labels, probabilities)\n","    return {\"roc_auc\": roc_auc}"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T13:22:23.148521Z","iopub.status.busy":"2024-05-17T13:22:23.148130Z","iopub.status.idle":"2024-05-17T13:22:24.068579Z","shell.execute_reply":"2024-05-17T13:22:24.067681Z","shell.execute_reply.started":"2024-05-17T13:22:23.148490Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Предобученная модель\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"DeepPavlov/rubert-base-cased\", num_labels=2).to(\"cuda\")"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T13:22:25.213602Z","iopub.status.busy":"2024-05-17T13:22:25.213219Z","iopub.status.idle":"2024-05-17T13:22:25.231694Z","shell.execute_reply":"2024-05-17T13:22:25.230480Z","shell.execute_reply.started":"2024-05-17T13:22:25.213572Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["# Гиперпараметры для обучения модели\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer = tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",")"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T13:22:26.629458Z","iopub.status.busy":"2024-05-17T13:22:26.629066Z","iopub.status.idle":"2024-05-17T13:27:33.673066Z","shell.execute_reply":"2024-05-17T13:27:33.671973Z","shell.execute_reply.started":"2024-05-17T13:22:26.629430Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/815 05:06 < 01:50, 1.95 it/s, Epoch 3/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Roc Auc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.670300</td>\n","      <td>0.668175</td>\n","      <td>0.634620</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.609400</td>\n","      <td>0.604002</td>\n","      <td>0.729847</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.626600</td>\n","      <td>0.639463</td>\n","      <td>0.734489</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.537600</td>\n","      <td>0.611068</td>\n","      <td>0.746775</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.499400</td>\n","      <td>0.619693</td>\n","      <td>0.765972</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.510100</td>\n","      <td>0.614261</td>\n","      <td>0.766037</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.436000</td>\n","      <td>0.651965</td>\n","      <td>0.773783</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.323400</td>\n","      <td>0.708034</td>\n","      <td>0.774195</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.319300</td>\n","      <td>0.704598</td>\n","      <td>0.777074</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.307100</td>\n","      <td>0.793847</td>\n","      <td>0.765053</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.171600</td>\n","      <td>0.930252</td>\n","      <td>0.757588</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.197800</td>\n","      <td>0.912964</td>\n","      <td>0.763891</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=600, training_loss=0.43405691146850583, metrics={'train_runtime': 306.5248, 'train_samples_per_second': 84.92, 'train_steps_per_second': 2.659, 'total_flos': 699438601794600.0, 'train_loss': 0.43405691146850583, 'epoch': 3.68})"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["# Обучение модели\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["#### Здесь у меня немного перемешались ячейки. Сначала я находила лучшую модель, потом её сжимала в zip и создавала ссылку для загрузкм."]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T12:33:57.772941Z","iopub.status.busy":"2024-05-17T12:33:57.772258Z","iopub.status.idle":"2024-05-17T12:35:27.266903Z","shell.execute_reply":"2024-05-17T12:35:27.265616Z","shell.execute_reply.started":"2024-05-17T12:33:57.772904Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/output/best_model/ (stored 0%)\n","  adding: kaggle/working/output/best_model/tokenizer.json (deflated 73%)\n","  adding: kaggle/working/output/best_model/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/output/best_model/training_args.bin (deflated 51%)\n","  adding: kaggle/working/output/best_model/tokenizer_config.json (deflated 75%)\n","  adding: kaggle/working/output/best_model/optimizer.pt (deflated 53%)\n","  adding: kaggle/working/output/best_model/vocab.txt (deflated 64%)\n","  adding: kaggle/working/output/best_model/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/output/best_model/config.json (deflated 53%)\n","  adding: kaggle/working/output/best_model/trainer_state.json (deflated 76%)\n","  adding: kaggle/working/output/best_model/model.safetensors (deflated 7%)\n","  adding: kaggle/working/output/best_model/special_tokens_map.json (deflated 42%)\n"]}],"source":["!zip -r best3.zip /kaggle/working/output/best_model"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T12:35:27.270511Z","iopub.status.busy":"2024-05-17T12:35:27.269539Z","iopub.status.idle":"2024-05-17T12:35:27.277819Z","shell.execute_reply":"2024-05-17T12:35:27.276809Z","shell.execute_reply.started":"2024-05-17T12:35:27.270469Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='best3.zip' target='_blank'>best3.zip</a><br>"],"text/plain":["/kaggle/working/best3.zip"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r'best3.zip')"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-17T12:32:50.013673Z","iopub.status.busy":"2024-05-17T12:32:50.012917Z","iopub.status.idle":"2024-05-17T12:33:22.889666Z","shell.execute_reply":"2024-05-17T12:33:22.888586Z","shell.execute_reply.started":"2024-05-17T12:32:50.013611Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='246' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41/41 00:32]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]}],"source":["import os\n","\n","# Среди сохраненных чекпоинтов выбирается в наилучшей метрикой\n","checkpoint_files = [f for f in os.listdir(training_args.output_dir) if f.startswith(\"checkpoint-\")]\n","\n","best_metric = float('-inf')\n","best_checkpoint = None\n","for checkpoint_file in checkpoint_files:\n","    \n","    trainer.model = AutoModelForSequenceClassification.from_pretrained(os.path.join(training_args.output_dir, checkpoint_file)).to('cuda')\n","\n","    result = trainer.evaluate()\n","\n","    if result[\"eval_roc_auc\"] > best_metric:\n","        best_metric = result[\"eval_roc_auc\"]\n","        best_checkpoint = checkpoint_file\n","\n","best_checkpoint_path = os.path.join(training_args.output_dir, best_checkpoint)\n","best_model_path = os.path.join(training_args.output_dir, \"best_model\")\n","os.rename(best_checkpoint_path, best_model_path)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5010378,"sourceId":8417177,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
